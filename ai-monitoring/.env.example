# AI Monitoring Demo App - Environment Configuration

# Ollama Configuration
OLLAMA_MODEL_A_URL=http://ollama-model-a:11434
OLLAMA_MODEL_B_URL=http://ollama-model-b:11434
MODEL_A_NAME=llama3.2:3b
MODEL_B_NAME=llama3.3:7b

# Agent Configuration
AGENT_PORT=8001
MCP_SERVER_URL=http://mcp-server:8002

# MCP Server Configuration
MCP_PORT=8002
DOCKER_HOST=unix:///var/run/docker.sock
LOCUST_URL=http://locust:8089

# Target App Configuration
TARGET_APP_PORT=8000
DATABASE_URL=postgresql://user:pass@fake-db:5432/app
LOG_LEVEL=INFO
FAILURE_STATE_FILE=/tmp/failure_state.json

# Chaos Engine Configuration
CHAOS_INTERVAL=180  # seconds between failure injections
CHAOS_ENABLED=true
TARGET_CONTAINER=ai-monitoring-target-app

# Locust Configuration
LOCUST_WEB_PORT=8089
TARGET_APP_URL=http://target-app:8000
AI_AGENT_URL=http://ai-agent:8001

# Streamlit Configuration
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=0.0.0.0
AGENT_URL=http://ai-agent:8001
MCP_URL=http://mcp-server:8002

# New Relic Configuration (For future instrumentation)
NEW_RELIC_LICENSE_KEY=
NEW_RELIC_APP_NAME=ai-monitoring-demo
NEW_RELIC_LOG_LEVEL=info
NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true
